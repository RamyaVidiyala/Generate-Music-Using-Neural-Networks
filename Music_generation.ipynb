{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import argparse\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from model import build_model, save_weights\n",
    "import numpy as np\n",
    "\n",
    "from model import build_model, load_weights\n",
    "\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import LSTM, Dropout, TimeDistributed, Dense, Activation, Embedding\n",
    "\n",
    "\n",
    "DATA_DIR = './data'\n",
    "LOG_DIR = './logs'\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "SEQ_LENGTH = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainLogger(object):\n",
    "    def __init__(self, file):\n",
    "        self.file = os.path.join(LOG_DIR, file)\n",
    "        self.epochs = 0\n",
    "        with open(self.file, 'w') as f:\n",
    "            f.write('epoch,loss,acc\\n')\n",
    "\n",
    "    def add_entry(self, loss, acc):\n",
    "        self.epochs += 1\n",
    "        s = '{},{},{}\\n'.format(self.epochs, loss, acc)\n",
    "        with open(self.file, 'a') as f:\n",
    "            f.write(s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def read_batches(T, vocab_size):\n",
    "    length = T.shape[0]; #129,665\n",
    "    batch_chars = int(length / BATCH_SIZE); # 8,104\n",
    "\n",
    "    for start in range(0, batch_chars - SEQ_LENGTH, SEQ_LENGTH): # (0, 8040, 64)\n",
    "        X = np.zeros((BATCH_SIZE, SEQ_LENGTH)) # 16X64\n",
    "        Y = np.zeros((BATCH_SIZE, SEQ_LENGTH, vocab_size)) # 16X64X86\n",
    "        for batch_idx in range(0, BATCH_SIZE): # (0,16)\n",
    "            for i in range(0, SEQ_LENGTH): #(0,64)\n",
    "                X[batch_idx, i] = T[batch_chars * batch_idx + start + i] # \n",
    "                Y[batch_idx, i, T[batch_chars * batch_idx + start + i + 1]] = 1\n",
    "        yield X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing\n",
      "Number of unique characters: 86\n",
      "processing done\n",
      "creating model\n",
      "model created\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (16, 64, 512)             44032     \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (16, 64, 256)             787456    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (16, 64, 256)             0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (16, 64, 256)             525312    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (16, 64, 256)             0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (16, 64, 256)             525312    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (16, 64, 256)             0         \n",
      "_________________________________________________________________\n",
      "time_distributed (TimeDistri (16, 64, 86)              22102     \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (16, 64, 86)              0         \n",
      "=================================================================\n",
      "Total params: 1,904,214\n",
      "Trainable params: 1,904,214\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "training data\n",
      "Length of text:129665\n",
      "\n",
      "Epoch 1/1\n",
      "[[51. 25.  1. ... 28.  0. 40.]\n",
      " [84. 29. 61. ... 29.  1. 34.]\n",
      " [47. 75. 58. ... 32. 33.  1.]\n",
      " ...\n",
      " [ 3. 29. 17. ... 22.  0. 47.]\n",
      " [22.  3. 28. ... 28. 84.  3.]\n",
      " [ 3. 33. 17. ...  3. 31.  3.]]\n",
      "Batch 1: loss = 4.454742431640625, acc = 0.0166015625\n",
      "[[25. 21. 14. ...  3. 28.  3.]\n",
      " [29. 61. 84. ...  1. 31. 33.]\n",
      " [28. 17. 34. ... 64. 84.  3.]\n",
      " ...\n",
      " [25. 41. 72. ... 78. 76. 66.]\n",
      " [31.  3. 63. ...  3. 28.  3.]\n",
      " [61. 17. 63. ...  0. 47. 25.]]\n",
      "Batch 2: loss = 4.432841777801514, acc = 0.1484375\n",
      "[[62. 60. 60. ... 60. 62.  1.]\n",
      " [28. 84.  0. ... 29. 84.  3.]\n",
      " [30.  3. 64. ...  1. 29. 17.]\n",
      " ...\n",
      " [60.  1. 31. ... 30.  0.  3.]\n",
      " [60. 17. 60. ... 17. 61. 84.]\n",
      " [50. 58. 68. ... 66. 58.  1.]]\n",
      "Batch 3: loss = 4.380638122558594, acc = 0.115234375\n",
      "[[58. 64. 26. ...  3. 28. 22.]\n",
      " [30.  3. 62. ...  1. 17. 18.]\n",
      " [28. 84.  3. ...  3. 31. 70.]\n",
      " ...\n",
      " [30.  3. 60. ... 34. 32.  1.]\n",
      " [ 3. 31.  3. ... 64. 63. 62.]\n",
      " [43. 65. 66. ...  3. 60. 17.]]\n",
      "Batch 4: loss = 4.123827934265137, acc = 0.1455078125\n",
      "[[ 3. 60. 29. ...  3. 31.  3.]\n",
      " [ 0. 47. 25. ... 75. 66. 64.]\n",
      " [ 3. 58. 18. ... 62. 62. 63.]\n",
      " ...\n",
      " [33. 32. 31. ... 56. 34. 17.]\n",
      " [84.  3. 28. ... 61.  1.  3.]\n",
      " [29.  1.  3. ...  3. 61. 29.]]\n",
      "Batch 5: loss = 3.7452220916748047, acc = 0.1611328125\n",
      "[[61. 18.  1. ...  1. 29. 58.]\n",
      " [64. 76. 11. ... 28. 22.  3.]\n",
      " [84.  3. 30. ...  3. 30.  3.]\n",
      " ...\n",
      " [32.  1.  3. ... 28. 29. 60.]\n",
      " [29. 70.  3. ... 17. 62. 84.]\n",
      " [34.  1.  3. ... 70.  3. 62.]]\n",
      "Batch 6: loss = 3.66882586479187, acc = 0.142578125\n",
      "[[75. 80. 62. ...  3. 28. 17.]\n",
      " [62. 17. 60. ... 29. 60. 84.]\n",
      " [62. 17. 61. ... 62.  1. 35.]\n",
      " ...\n",
      " [84.  3. 32. ... 28. 70.  3.]\n",
      " [ 3. 31.  3. ... 58. 77. 58.]\n",
      " [60. 28. 84. ... 31. 17. 29.]]\n",
      "Batch 7: loss = 3.616271495819092, acc = 0.0859375\n",
      "[[28. 84.  3. ...  1.  3. 34.]\n",
      " [ 3. 31.  3. ... 29. 60. 84.]\n",
      " [78. 71. 77. ... 25. 21. 14.]\n",
      " ...\n",
      " [28. 18.  1. ... 77. 77. 66.]\n",
      " [59. 58. 76. ... 29.  1. 28.]\n",
      " [ 1. 60. 17. ...  3. 28. 60.]]\n",
      "Batch 8: loss = 3.560462474822998, acc = 0.08203125\n",
      "[[ 3. 34. 18. ...  3. 34.  3.]\n",
      " [ 3. 31.  3. ...  1. 61. 17.]\n",
      " [23.  0. 38. ... 32. 70.  3.]\n",
      " ...\n",
      " [71. 64. 65. ... 30.  3. 58.]\n",
      " [34. 33. 84. ... 17. 25. 84.]\n",
      " [62.  1. 61. ...  1. 40. 78.]]\n",
      "Batch 9: loss = 3.628173351287842, acc = 0.0771484375\n",
      "[[64. 17. 64. ...  1. 34. 17.]\n",
      " [25. 84.  0. ... 38. 62. 79.]\n",
      " [62. 60. 28. ... 62. 61. 60.]\n",
      " ...\n",
      " [18.  1. 64. ... 33.  3. 58.]\n",
      " [ 0. 43. 25. ...  3. 29. 29.]\n",
      " [76. 66. 60. ...  3. 61. 17.]]\n",
      "Batch 10: loss = 3.577927589416504, acc = 0.125\n",
      "[[33. 84. 84. ...  3. 28. 29.]\n",
      " [66. 71.  1. ... 30.  3. 28.]\n",
      " [ 1.  3. 31. ... 28.  1. 28.]\n",
      " ...\n",
      " [18.  1. 58. ... 61. 84.  3.]\n",
      " [29.  1. 29. ... 34. 84.  3.]\n",
      " [28.  1. 12. ... 17. 28.  1.]]\n",
      "Batch 11: loss = 3.413236141204834, acc = 0.1552734375\n",
      "[[60. 84.  0. ... 29.  1. 62.]\n",
      " [34. 32. 84. ... 84.  3. 34.]\n",
      " [58. 64. 84. ...  0.  0.  0.]\n",
      " ...\n",
      " [31. 22.  3. ... 60.  1. 29.]\n",
      " [31. 22.  3. ... 70.  1. 40.]\n",
      " [12.  3. 28. ... 84.  3. 31.]]\n",
      "Batch 12: loss = 3.4859752655029297, acc = 0.1640625\n",
      "[[17. 62. 84. ... 62. 17. 62.]\n",
      " [ 3. 31. 34. ... 30.  3. 64.]\n",
      " [51. 25.  1. ...  1. 38. 66.]\n",
      " ...\n",
      " [17. 60. 84. ... 18.  1. 58.]\n",
      " [78. 76. 66. ... 33.  1. 34.]\n",
      " [ 3. 33. 34. ... 84. 54.  0.]]\n",
      "Batch 13: loss = 3.5393099784851074, acc = 0.1435546875\n",
      "[[84.  0.  3. ... 18.  0. 47.]\n",
      " [63. 62. 84. ... 28. 84.  3.]\n",
      " [75. 68. 73. ... 32. 84.  3.]\n",
      " ...\n",
      " [17. 56. 58. ... 58. 18. 84.]\n",
      " [17. 61. 84. ...  1. 12. 34.]\n",
      " [ 3. 32. 70. ... 70.  1. 40.]]\n",
      "Batch 14: loss = 3.498975992202759, acc = 0.1455078125\n",
      "[[25. 47. 65. ...  0. 40. 25.]\n",
      " [34.  3. 29. ... 58. 76. 62.]\n",
      " [34.  3. 31. ... 29. 11. 34.]\n",
      " ...\n",
      " [ 3. 34. 22. ...  1. 40. 78.]\n",
      " [17. 25. 25. ... 64. 58. 59.]\n",
      " [78. 76. 66. ... 29.  1.  3.]]\n",
      "Batch 15: loss = 3.531930446624756, acc = 0.1396484375\n",
      "[[21. 14. 23. ... 22.  3.  1.]\n",
      " [ 0. 52. 25. ... 31.  1. 31.]\n",
      " [11.  1. 31. ... 30.  1.  3.]\n",
      " ...\n",
      " [76. 66. 60. ... 84.  3. 34.]\n",
      " [84.  3. 30. ... 72. 75.  1.]\n",
      " [32. 70.  3. ... 29. 17. 56.]]\n",
      "Batch 16: loss = 3.4190330505371094, acc = 0.138671875\n",
      "[[62. 17.  1. ...  1. 61. 17.]\n",
      " [32. 34. 84. ... 34.  1. 28.]\n",
      " [33.  3. 33. ...  1. 28. 17.]\n",
      " ...\n",
      " [ 3. 61. 56. ...  3. 32. 70.]\n",
      " [58.  1. 45. ... 28.  0. 84.]\n",
      " [60. 84. 54. ...  3. 32. 70.]]\n",
      "Batch 17: loss = 3.3994626998901367, acc = 0.154296875\n",
      "[[25. 84.  0. ...  3. 62. 17.]\n",
      " [29. 60. 84. ... 29. 34. 32.]\n",
      " [34. 84. 33. ... 33. 17. 28.]\n",
      " ...\n",
      " [ 3. 29. 34. ...  3. 30.  3.]\n",
      " [64. 84.  1. ... 84.  3. 34.]\n",
      " [ 3. 34. 17. ... 29. 18.  1.]]\n",
      "Batch 18: loss = 3.283130168914795, acc = 0.1591796875\n",
      "[[ 1. 64. 84. ...  0. 51. 25.]\n",
      " [84.  3. 34. ... 34.  1. 28.]\n",
      " [84.  1.  3. ... 66. 71. 64.]\n",
      " ...\n",
      " [64. 63. 62. ... 63. 62.  1.]\n",
      " [ 3. 34. 17. ... 63. 17. 63.]\n",
      " [12. 29. 17. ... 12. 64. 17.]]\n",
      "Batch 19: loss = 3.5331082344055176, acc = 0.1318359375\n",
      "[[ 1. 19.  0. ...  1. 73.  1.]\n",
      " [34. 32. 84. ... 34. 32. 84.]\n",
      " [65. 58. 70. ... 25. 21. 14.]\n",
      " ...\n",
      " [ 3. 34.  3. ... 62. 79. 62.]\n",
      " [ 1. 63. 62. ... 84.  3. 28.]\n",
      " [63. 84. 64. ...  3. 29. 17.]]\n",
      "Batch 20: loss = 3.477001428604126, acc = 0.1298828125\n",
      "[[19. 21. 11. ... 34.  3. 61.]\n",
      " [ 3. 28. 70. ... 34. 32. 31.]\n",
      " [23.  0. 38. ... 17. 29.  1.]\n",
      " ...\n",
      " [71.  1. 46. ...  1. 79. 66.]\n",
      " [22.  3. 58. ... 58. 77. 58.]\n",
      " [61. 84. 54. ... 40. 78. 76.]]\n",
      "Batch 21: loss = 3.5111210346221924, acc = 0.1318359375\n",
      "[[62. 61.  1. ... 60. 29. 28.]\n",
      " [ 1. 31. 17. ... 62. 79. 66.]\n",
      " [29. 28. 29. ... 64. 17. 64.]\n",
      " ...\n",
      " [58.  1. 52. ...  3. 29. 60.]\n",
      " [59. 58. 76. ...  3. 28.  3.]\n",
      " [66. 60.  1. ... 84.  3. 34.]]\n",
      "Batch 22: loss = 3.4660110473632812, acc = 0.1376953125\n",
      "[[84.  3. 34. ... 61. 64. 29.]\n",
      " [71.  1. 29. ... 62. 84.  3.]\n",
      " [ 1. 64. 18. ... 22.  3. 62.]\n",
      " ...\n",
      " [61.  1.  3. ... 64. 84.  1.]\n",
      " [28. 60. 62. ...  3. 58. 64.]\n",
      " [ 3. 34. 17. ... 31. 22.  3.]]\n",
      "Batch 23: loss = 3.294177532196045, acc = 0.1708984375\n",
      "[[84.  3. 28. ... 28. 22.  3.]\n",
      " [31.  3. 63. ... 17. 61.  1.]\n",
      " [61. 60. 84. ... 66. 60.  1.]\n",
      " ...\n",
      " [53. 16.  3. ...  3. 28.  3.]\n",
      " [63.  1.  3. ... 64. 58. 84.]\n",
      " [28. 29. 60. ... 28. 70.  3.]]\n",
      "Batch 24: loss = 3.434953212738037, acc = 0.1513671875\n",
      "[[63. 64. 62. ...  1. 31. 58.]\n",
      " [61. 17. 61. ... 58. 17. 58.]\n",
      " [31. 58. 77. ... 28.  1. 28.]\n",
      " ...\n",
      " [62. 63. 64. ... 62. 63. 64.]\n",
      " [ 3. 31.  3. ... 28.  3. 28.]\n",
      " [60. 61. 62. ...  1.  3. 31.]]\n",
      "Batch 25: loss = 3.413236141204834, acc = 0.15625\n",
      "[[77. 58. 59. ... 84.  3. 32.]\n",
      " [84.  3. 28. ... 14. 64. 10.]\n",
      " [33. 28. 84. ... 28. 22.  3.]\n",
      " ...\n",
      " [84.  3. 28. ... 59. 58. 76.]\n",
      " [17. 25. 84. ... 45. 46. 30.]\n",
      " [22.  3. 61. ... 64. 58. 59.]]\n",
      "Batch 26: loss = 3.403815746307373, acc = 0.150390625\n",
      "[[22.  3. 29. ...  3. 29. 28.]\n",
      " [ 3. 62. 17. ...  3. 63. 17.]\n",
      " [62. 63. 64. ... 32. 32. 84.]\n",
      " ...\n",
      " [62.  0. 46. ...  3. 31.  3.]\n",
      " [31. 46.  1. ... 22.  3. 62.]\n",
      " [ 1. 64. 17. ... 58. 17. 64.]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 27: loss = 3.14103102684021, acc = 0.193359375\n",
      "[[29.  1.  3. ... 28. 84.  3.]\n",
      " [63. 84.  3. ... 18.  1.  3.]\n",
      " [ 3. 34.  3. ... 31.  3. 63.]\n",
      " ...\n",
      " [28. 33. 31. ...  3. 34. 18.]\n",
      " [61. 60. 84. ... 60. 84.  3.]\n",
      " [84.  3. 30. ... 34. 70.  3.]]\n",
      "Batch 28: loss = 3.301115036010742, acc = 0.1728515625\n",
      "[[28.  3. 62. ...  3. 28.  3.]\n",
      " [34.  3. 61. ...  3. 31.  3.]\n",
      " [61. 61.  1. ... 25. 40. 66.]\n",
      " ...\n",
      " [ 1.  3. 29. ...  3. 29. 60.]\n",
      " [31.  3. 61. ...  1.  3. 28.]\n",
      " [64. 17. 34. ... 61. 60. 29.]]\n",
      "Batch 29: loss = 3.397311210632324, acc = 0.1494140625\n",
      "[[58. 62. 60. ... 25. 33. 72.]\n",
      " [63. 17. 64. ...  1. 46. 72.]\n",
      " [68. 62.  1. ... 28. 84.  3.]\n",
      " ...\n",
      " [28.  1.  3. ...  0.  3. 32.]\n",
      " [22.  3. 29. ... 17. 33. 84.]\n",
      " [ 1. 28. 34. ... 65. 58. 70.]]\n",
      "Batch 30: loss = 3.347227096557617, acc = 0.1435546875\n",
      "[[75. 70. 58. ... 17. 29. 14.]\n",
      " [ 1. 29. 69. ... 33.  0. 40.]\n",
      " [34.  3. 29. ...  3. 34.  3.]\n",
      " ...\n",
      " [70.  3. 29. ... 34. 84.  3.]\n",
      " [ 3. 34.  3. ... 28.  3. 32.]\n",
      " [ 1. 40. 78. ... 84.  3. 28.]]\n",
      "Batch 31: loss = 3.249284505844116, acc = 0.1552734375\n",
      "[[17. 84. 28. ... 40. 25. 21.]\n",
      " [25. 19. 14. ... 61. 17. 62.]\n",
      " [29. 34. 32. ...  1. 63. 61.]\n",
      " ...\n",
      " [31.  3. 33. ... 61. 66. 64.]\n",
      " [17. 28.  1. ... 62. 84.  0.]\n",
      " [ 3. 60. 18. ... 62.  1. 61.]]\n",
      "Batch 32: loss = 3.3391714096069336, acc = 0.1337890625\n",
      "[[14. 23.  0. ...  1. 28. 34.]\n",
      " [ 1. 64. 63. ... 25. 29.  0.]\n",
      " [61. 84.  3. ...  3. 61. 18.]\n",
      " ...\n",
      " [ 0.  5.  1. ... 45. 72. 80.]\n",
      " [ 3. 31. 22. ... 18.  1. 61.]\n",
      " [60. 29. 84. ... 32. 28. 60.]]\n",
      "Batch 33: loss = 3.273256778717041, acc = 0.15234375\n",
      "[[33. 84. 32. ... 31.  1. 32.]\n",
      " [84. 25. 61. ... 63. 84.  3.]\n",
      " [ 1. 61. 60. ...  3. 34. 29.]\n",
      " ...\n",
      " [62.  0. 40. ...  3. 62. 18.]\n",
      " [17. 84. 84. ... 43. 58. 78.]\n",
      " [ 1. 62. 61. ... 60. 29. 84.]]\n",
      "Batch 34: loss = 3.251103401184082, acc = 0.154296875\n",
      "[[31. 30. 84. ... 17. 63.  1.]\n",
      " [30. 14. 62. ...  3. 28. 70.]\n",
      " [29.  1.  3. ... 66. 75. 60.]\n",
      " ...\n",
      " [ 1.  3. 32. ... 84.  3. 28.]\n",
      " [69. 66. 71. ... 34.  3. 29.]\n",
      " [53. 16.  3. ... 50. 66. 63.]]\n",
      "Batch 35: loss = 3.2006759643554688, acc = 0.1494140625\n",
      "[[63. 62. 63. ... 17. 62. 84.]\n",
      " [ 3.  1. 28. ...  3. 34. 22.]\n",
      " [69. 62.  1. ... 79. 66. 58.]\n",
      " ...\n",
      " [ 3. 60. 62. ...  1. 31. 32.]\n",
      " [18.  1. 61. ...  3. 62. 17.]\n",
      " [62.  0.  5. ... 25. 21. 14.]]\n",
      "Batch 36: loss = 3.3504037857055664, acc = 0.1435546875\n",
      "[[84.  0. 38. ... 61. 60. 84.]\n",
      " [ 3.  1. 62. ...  0. 51. 25.]\n",
      " [ 1. 43. 65. ... 17. 33.  1.]\n",
      " ...\n",
      " [33. 84.  3. ... 18.  1. 12.]\n",
      " [28.  1. 29. ... 64. 17. 61.]\n",
      " [23.  0. 38. ... 32. 22.  3.]]\n",
      "Batch 37: loss = 3.3050389289855957, acc = 0.130859375\n",
      "[[ 0. 43. 25. ... 60.  1. 31.]\n",
      " [ 1. 17. 23. ...  1. 16.  1.]\n",
      " [34. 33. 32. ...  3. 31. 22.]\n",
      " ...\n",
      " [29. 17. 32. ...  3. 28.  3.]\n",
      " [ 1. 62. 17. ... 28. 21. 12.]\n",
      " [32. 17. 32. ... 17. 84. 84.]]\n",
      "Batch 38: loss = 3.2785816192626953, acc = 0.1376953125\n",
      "[[58. 77. 58. ... 70.  3. 33.]\n",
      " [73.  1. 19. ... 28. 22.  3.]\n",
      " [ 3. 61. 17. ... 33. 32. 84.]\n",
      " ...\n",
      " [28. 18.  1. ... 62.  1.  3.]\n",
      " [84. 28. 18. ...  1. 60. 17.]\n",
      " [ 0. 43. 25. ... 61. 29. 84.]]\n",
      "Batch 39: loss = 3.2367336750030518, acc = 0.1435546875\n",
      "[[34. 33.  1. ... 84.  0.  3.]\n",
      " [61. 63. 59. ... 31.  3. 61.]\n",
      " [ 3. 34.  3. ... 30.  3. 32.]\n",
      " ...\n",
      " [32.  3. 61. ... 76. 66. 60.]\n",
      " [61. 84.  3. ... 77. 66. 71.]\n",
      " [ 0.  3. 32. ...  3. 28.  3.]]\n",
      "Batch 40: loss = 3.216315269470215, acc = 0.158203125\n",
      "[[34.  3. 62. ... 33. 17. 28.]\n",
      " [18.  1. 61. ... 31.  3. 58.]\n",
      " [34. 32. 84. ...  3. 28.  3.]\n",
      " ...\n",
      " [ 1. 31. 58. ...  9.  3. 62.]\n",
      " [64. 65. 58. ...  0. 38. 25.]\n",
      " [32. 28. 60. ... 29. 84.  3.]]\n",
      "Batch 41: loss = 3.2099642753601074, acc = 0.1484375\n",
      "[[ 1. 61. 17. ... 33. 17. 32.]\n",
      " [18.  1.  3. ... 28. 22.  3.]\n",
      " [32. 28. 60. ...  3. 62. 18.]\n",
      " ...\n",
      " [17. 61.  1. ... 17. 60. 84.]\n",
      " [31.  0.  3. ... 34. 84.  3.]\n",
      " [28.  3. 28. ...  1. 31. 58.]]\n",
      "Batch 42: loss = 3.120986223220825, acc = 0.177734375\n",
      "[[84.  3. 31. ... 34.  3. 29.]\n",
      " [28. 18. 84. ... 62. 63. 84.]\n",
      " [ 1. 62. 17. ... 25. 47. 65.]\n",
      " ...\n",
      " [ 0.  3. 32. ... 34. 17. 29.]\n",
      " [31.  3. 28. ...  3. 34. 60.]\n",
      " [77. 58. 59. ... 61. 84.  3.]]\n",
      "Batch 43: loss = 3.1336774826049805, acc = 0.1767578125\n",
      "[[18.  1. 61. ... 28. 17. 28.]\n",
      " [ 3. 29. 70. ... 70. 62.  0.]\n",
      " [62.  1. 30. ... 25. 21. 14.]\n",
      " ...\n",
      " [84.  3. 28. ... 28. 18.  1.]\n",
      " [34.  1. 60. ... 16.  3. 28.]\n",
      " [30.  3. 62. ...  3. 28. 70.]]\n",
      "Batch 44: loss = 3.263458251953125, acc = 0.158203125\n",
      "[[84.  0.  3. ... 84.  3. 31.]\n",
      " [ 5.  1. 41. ...  0. 38. 25.]\n",
      " [23.  0. 38. ...  3. 28. 33.]\n",
      " ...\n",
      " [12. 28. 17. ... 32.  3. 29.]\n",
      " [22.  3. 34. ... 71. 64. 65.]\n",
      " [ 3. 60. 28. ... 33. 34. 84.]]\n",
      "Batch 45: loss = 3.2378668785095215, acc = 0.15625\n",
      "[[ 3. 31. 18. ... 59. 58. 76.]\n",
      " [28. 70.  0. ... 33.  3. 60.]\n",
      " [31. 84.  0. ...  3. 31.  3.]\n",
      " ...\n",
      " [18.  1. 12. ...  1. 64. 63.]\n",
      " [58. 70.  1. ... 84.  3. 32.]\n",
      " [ 0.  3. 28. ... 25. 50. 65.]]\n",
      "Batch 46: loss = 3.1844067573547363, acc = 0.166015625\n",
      "[[62.  0. 52. ...  3. 62. 18.]\n",
      " [29. 28.  1. ...  3. 30.  3.]\n",
      " [63. 58. 61. ... 22.  3. 62.]\n",
      " ...\n",
      " [62. 84.  0. ... 84.  0.  0.]\n",
      " [70.  3. 34. ...  3. 61. 56.]\n",
      " [62. 71.  1. ... 66. 71.  1.]]\n",
      "Batch 47: loss = 3.2154860496520996, acc = 0.16796875\n",
      "[[ 1. 62. 60. ... 28.  1.  3.]\n",
      " [60. 61. 62. ... 61. 60. 84.]\n",
      " [63. 64. 84. ... 41. 72. 77.]\n",
      " ...\n",
      " [ 0. 51. 25. ... 75. 66. 64.]\n",
      " [60. 61.  1. ... 60. 61.  1.]\n",
      " [29. 75. 66. ... 29. 60.  1.]]\n",
      "Batch 48: loss = 3.153773069381714, acc = 0.171875\n",
      "[[32. 22.  3. ...  3. 31.  3.]\n",
      " [ 3. 32. 22. ... 66. 60.  1.]\n",
      " [77. 66. 71. ... 43. 25. 28.]\n",
      " ...\n",
      " [64. 76. 11. ... 29. 34. 32.]\n",
      " [ 3. 32. 70. ... 34. 33. 84.]\n",
      " [ 3. 31. 22. ... 34. 18.  1.]]\n",
      "Batch 49: loss = 3.249722719192505, acc = 0.146484375\n",
      "[[28. 61. 63. ... 62. 14. 17.]\n",
      " [31. 58. 77. ...  3. 32. 70.]\n",
      " [ 0. 62. 14. ...  3. 28.  3.]\n",
      " ...\n",
      " [ 1. 32. 34. ... 28. 84.  3.]\n",
      " [ 3. 32. 70. ... 59. 58. 76.]\n",
      " [12. 34. 17. ... 34.  3. 34.]]\n",
      "Batch 50: loss = 3.1717400550842285, acc = 0.154296875\n",
      "[[58. 18. 14. ...  3. 58. 62.]\n",
      " [ 3. 64. 63. ... 70.  3. 62.]\n",
      " [60. 61. 60. ... 14. 17. 84.]\n",
      " ...\n",
      " [31.  3. 61. ... 63. 64. 84.]\n",
      " [62.  0. 52. ... 17. 34.  1.]\n",
      " [17. 28.  1. ... 84.  3. 31.]]\n",
      "Batch 51: loss = 3.1504948139190674, acc = 0.158203125\n",
      "[[62.  1. 62. ... 29.  1.  3.]\n",
      " [60. 28.  1. ...  3. 58. 64.]\n",
      " [ 3. 28.  3. ... 62.  1.  3.]\n",
      " ...\n",
      " [ 0.  3. 31. ... 65. 58. 71.]\n",
      " [ 3. 31. 22. ... 28. 33. 31.]\n",
      " [22.  3. 33. ... 70.  3. 61.]]\n",
      "Batch 52: loss = 3.1174869537353516, acc = 0.1728515625\n",
      "[[28.  3. 28. ... 29. 34. 29.]\n",
      " [63. 84.  3. ... 53. 16.  3.]\n",
      " [31.  3. 63. ... 58. 66. 71.]\n",
      " ...\n",
      " [62.  7. 76. ... 14. 23.  0.]\n",
      " [84.  3. 34. ... 34. 84.  3.]\n",
      " [17. 29.  1. ... 40. 78. 76.]]\n",
      "Batch 53: loss = 3.21025013923645, acc = 0.1513671875\n",
      "[[84.  0.  3. ...  0. 51. 25.]\n",
      " [32. 70.  3. ...  1. 41. 72.]\n",
      " [62.  0.  5. ... 70.  0. 32.]\n",
      " ...\n",
      " [38. 25. 34. ... 34.  3. 61.]\n",
      " [32. 70.  3. ... 17. 33.  1.]\n",
      " [66. 60.  1. ...  3. 61. 29.]]\n",
      "Batch 54: loss = 3.2601447105407715, acc = 0.1552734375\n",
      "[[ 1. 24.  0. ... 76.  1. 39.]\n",
      " [77. 77. 66. ...  3. 32. 28.]\n",
      " [84.  3. 28. ... 60. 84.  3.]\n",
      " ...\n",
      " [29. 34.  1. ... 84.  3. 34.]\n",
      " [34. 17.  3. ... 60. 61. 84.]\n",
      " [34.  1.  3. ...  3. 30.  3.]]\n",
      "Batch 55: loss = 3.2791213989257812, acc = 0.154296875\n",
      "[[ 1. 31. 72. ... 84.  3. 32.]\n",
      " [28.  1. 28. ... 84.  3. 28.]\n",
      " [32. 22.  3. ... 64. 17. 56.]\n",
      " ...\n",
      " [ 3. 61. 29. ... 61. 84.  3.]\n",
      " [ 3. 31.  3. ... 30.  3. 29.]\n",
      " [60. 61. 62. ... 64. 17. 58.]]\n",
      "Batch 56: loss = 3.1544079780578613, acc = 0.1552734375\n",
      "[[70.  3. 32. ... 63. 84. 62.]\n",
      " [70.  3. 62. ... 34. 34.  1.]\n",
      " [64. 84.  3. ... 84.  3. 28.]\n",
      " ...\n",
      " [30.  3. 62. ... 51. 25.  1.]\n",
      " [17. 60. 84. ...  5.  1. 41.]\n",
      " [84.  3. 32. ... 70.  3. 62.]]\n",
      "Batch 57: loss = 3.1329426765441895, acc = 0.1845703125\n",
      "[[17. 61.  1. ... 60. 84.  3.]\n",
      " [61. 34. 34. ... 28.  1. 28.]\n",
      " [70.  3. 60. ... 59. 69. 62.]\n",
      " ...\n",
      " [17. 23. 21. ... 71. 71. 62.]\n",
      " [72. 77. 77. ... 14. 17. 29.]\n",
      " [18.  1. 12. ... 65. 58. 70.]]\n",
      "Batch 58: loss = 3.2053322792053223, acc = 0.146484375\n",
      "[[31.  3. 61. ... 78. 69. 66.]\n",
      " [17. 63. 84. ... 29. 61. 84.]\n",
      " [76.  0.  5. ...  0. 28. 84.]\n",
      " ...\n",
      " [61. 82. 11. ... 34. 17. 34.]\n",
      " [14. 17. 56. ... 18.  1. 28.]\n",
      " [ 1. 40. 78. ... 28. 70.  0.]]\n",
      "Batch 59: loss = 3.227497100830078, acc = 0.158203125\n",
      "[[71. 62.  1. ... 33. 32. 31.]\n",
      " [ 3. 28. 70. ... 78. 71. 72.]\n",
      " [ 3. 31.  3. ... 28. 28.  1.]\n",
      " ...\n",
      " [ 1. 34. 17. ... 70.  3. 61.]\n",
      " [33. 28. 84. ... 84. 25.  3.]\n",
      " [ 3. 28. 70. ... 56. 63. 64.]]\n",
      "Batch 60: loss = 3.1385927200317383, acc = 0.158203125\n",
      "[[ 1. 28. 34. ...  0. 31. 84.]\n",
      " [ 0.  5.  1. ... 40. 25. 21.]\n",
      " [61. 28. 28. ... 59. 59. 84.]\n",
      " ...\n",
      " [18.  1. 61. ...  1. 32. 18.]\n",
      " [33.  3. 28. ... 84. 58. 60.]\n",
      " [ 1. 62. 17. ... 34.  3. 61.]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 61: loss = 3.1540369987487793, acc = 0.1650390625\n",
      "[[ 3. 34.  3. ... 31. 22.  3.]\n",
      " [14. 23.  0. ... 26. 29. 28.]\n",
      " [ 3. 31.  3. ...  1. 61. 62.]\n",
      " ...\n",
      " [84.  0.  3. ... 23. 22.  0.]\n",
      " [ 7. 58.  1. ... 51. 25.  1.]\n",
      " [29. 34.  1. ... 28.  1. 62.]]\n",
      "Batch 62: loss = 3.0938234329223633, acc = 0.181640625\n",
      "[[28. 29. 28. ... 64.  0.  5.]\n",
      " [84.  0.  3. ... 25.  0. 58.]\n",
      " [63. 84.  3. ... 61.  0.  5.]\n",
      " ...\n",
      " [47. 25. 47. ... 65. 58. 70.]\n",
      " [18. 15. 24. ... 45. 72. 80.]\n",
      " [28. 62. 84. ... 84. 62. 17.]]\n",
      "Batch 63: loss = 3.2291955947875977, acc = 0.158203125\n",
      "[[ 1. 41. 72. ...  3. 61. 17.]\n",
      " [84.  3. 31. ...  1. 59. 58.]\n",
      " [ 1. 41. 72. ... 31. 33. 28.]\n",
      " ...\n",
      " [ 1. 40. 78. ... 34.  3. 64.]\n",
      " [62.  0. 40. ... 61. 60. 84.]\n",
      " [61.  1. 64. ...  3. 28. 70.]]\n",
      "Batch 64: loss = 3.213397979736328, acc = 0.146484375\n",
      "[[59.  1. 59. ... 64.  1. 64.]\n",
      " [64. 84.  3. ... 66. 64.  0.]\n",
      " [84.  3. 31. ...  3. 31.  3.]\n",
      " ...\n",
      " [17. 34.  1. ... 30.  3. 32.]\n",
      " [ 0.  3. 34. ...  3. 30.  3.]\n",
      " [ 3. 62. 17. ...  0.  0. 51.]]\n",
      "Batch 65: loss = 3.0897982120513916, acc = 0.1591796875\n",
      "[[17. 64. 84. ... 64.  1. 59.]\n",
      " [ 5.  1. 41. ... 84. 63. 14.]\n",
      " [61. 62. 61. ...  3. 62. 60.]\n",
      " ...\n",
      " [34. 34.  1. ... 61.  1. 61.]\n",
      " [60. 61. 62. ... 17. 60.  1.]\n",
      " [25.  1. 18. ... 78. 58. 69.]]\n",
      "Batch 66: loss = 3.110912561416626, acc = 0.1689453125\n",
      "[[64. 62. 84. ... 84.  3. 34.]\n",
      " [17. 58. 18. ...  1. 29. 14.]\n",
      " [28.  1. 28. ...  1. 31. 33.]\n",
      " ...\n",
      " [29. 34. 84. ... 61. 62. 63.]\n",
      " [ 3. 31. 22. ... 77. 58. 59.]\n",
      " [11.  1. 79. ... 31. 17. 31.]]\n",
      "Batch 67: loss = 3.162571430206299, acc = 0.166015625\n",
      "[[ 3. 34. 29. ... 77. 58. 59.]\n",
      " [17. 61. 18. ... 17. 61. 84.]\n",
      " [28. 84.  3. ... 41. 72. 77.]\n",
      " ...\n",
      " [84.  3. 32. ... 72. 77. 77.]\n",
      " [58. 76. 62. ... 64.  1. 63.]\n",
      " [84.  3. 30. ...  3. 29. 17.]]\n",
      "Batch 68: loss = 3.186009407043457, acc = 0.158203125\n",
      "[[58. 76. 62. ... 32. 18.  1.]\n",
      " [ 3. 34.  3. ... 60. 29. 28.]\n",
      " [77. 66. 71. ... 38. 25. 31.]\n",
      " ...\n",
      " [66. 71. 64. ... 17. 84.  3.]\n",
      " [62. 61. 84. ... 62. 61.  1.]\n",
      " [28. 84.  3. ...  3. 29. 18.]]\n",
      "Batch 69: loss = 3.123450517654419, acc = 0.16796875\n",
      "[[29. 17. 28. ... 30.  3. 34.]\n",
      " [84.  3. 31. ... 63. 64. 25.]\n",
      " [ 0. 29. 84. ... 84. 63. 62.]\n",
      " ...\n",
      " [31.  3. 58. ...  3. 31.  3.]\n",
      " [61. 17. 25. ... 31.  3. 31.]\n",
      " [ 1. 29. 60. ... 25. 84.  0.]]\n",
      "Batch 70: loss = 3.036101818084717, acc = 0.1787109375\n",
      "[[17. 33. 84. ... 28. 18.  1.]\n",
      " [84.  0.  1. ... 76. 66. 60.]\n",
      " [61.  1. 28. ...  3. 28. 60.]\n",
      " ...\n",
      " [58. 59. 58. ... 58. 59. 58.]\n",
      " [33. 28.  1. ... 47. 25. 47.]\n",
      " [ 0.  0. 51. ... 58. 75. 75.]]\n",
      "Batch 71: loss = 3.1351051330566406, acc = 0.1669921875\n",
      "[[60. 17. 29. ... 72. 77. 77.]\n",
      " [ 1. 31. 58. ... 61. 84.  3.]\n",
      " [60.  1. 60. ... 61. 18.  1.]\n",
      " ...\n",
      " [ 1.  3. 28. ... 60. 29. 84.]\n",
      " [58. 70.  7. ... 28. 29.  0.]\n",
      " [ 1. 43. 65. ... 29. 84.  3.]]\n",
      "Batch 72: loss = 3.170665740966797, acc = 0.177734375\n",
      "[[66. 71. 64. ...  0. 29. 14.]\n",
      " [28. 70.  3. ...  3. 28. 70.]\n",
      " [12. 61. 17. ... 25. 47. 75.]\n",
      " ...\n",
      " [ 3. 31.  3. ... 61. 17. 60.]\n",
      " [40. 25. 21. ... 17. 62. 84.]\n",
      " [28.  3. 60. ...  3. 28.  3.]]\n",
      "Batch 73: loss = 3.100280523300171, acc = 0.17578125\n",
      "[[17. 28. 14. ... 17. 29. 84.]\n",
      " [ 3. 62. 17. ... 62. 60. 84.]\n",
      " [58. 61. 11. ...  1.  3. 28.]\n",
      " ...\n",
      " [84.  3. 34. ... 22.  3. 32.]\n",
      " [ 3. 31. 70. ... 62. 17. 25.]\n",
      " [28. 11. 29. ... 61. 84.  3.]]\n",
      "Batch 74: loss = 3.035527229309082, acc = 0.1796875\n",
      "[[ 0.  3. 34. ... 25. 29.  0.]\n",
      " [ 3. 34.  3. ...  3. 32. 22.]\n",
      " [ 3. 32. 33. ... 84.  0. 62.]\n",
      " ...\n",
      " [18.  1. 33. ... 29. 84.  3.]\n",
      " [84. 53. 17. ...  0.  3. 34.]\n",
      " [28.  3. 60. ... 32. 22.  3.]]\n",
      "Batch 75: loss = 3.0142033100128174, acc = 0.1748046875\n",
      "[[84. 25. 29. ... 62. 29. 62.]\n",
      " [ 3. 61. 62. ... 77. 77. 66.]\n",
      " [84.  3. 31. ...  1. 61. 17.]\n",
      " ...\n",
      " [31.  3. 28. ... 61.  1. 46.]\n",
      " [22.  3. 64. ... 16. 17.  0.]\n",
      " [61. 17. 29. ...  1. 34. 17.]]\n",
      "Batch 76: loss = 3.1168668270111084, acc = 0.171875\n",
      "[[ 1.  3. 32. ... 17. 25. 84.]\n",
      " [71. 64. 65. ...  1. 63. 17.]\n",
      " [60. 84.  0. ...  3. 60. 29.]\n",
      " ...\n",
      " [65. 66. 73. ... 25. 31.  0.]\n",
      " [47. 25. 31. ...  1. 32. 33.]\n",
      " [29. 84.  3. ... 32. 18. 84.]]\n",
      "Batch 77: loss = 3.021369218826294, acc = 0.197265625\n",
      "[[53. 17.  3. ... 58. 77. 58.]\n",
      " [58. 84.  3. ...  3. 64. 63.]\n",
      " [28. 84.  0. ...  0. 51. 25.]\n",
      " ...\n",
      " [28. 84.  3. ...  3. 62. 60.]\n",
      " [ 0. 52. 25. ... 28.  1.  3.]\n",
      " [ 3. 31.  3. ... 25.  1. 18.]]\n",
      "Batch 78: loss = 2.984117031097412, acc = 0.1806640625\n",
      "[[59. 58. 76. ... 34.  3. 61.]\n",
      " [64.  1.  3. ... 29.  1. 29.]\n",
      " [ 1. 20. 23. ... 76. 77. 11.]\n",
      " ...\n",
      " [28. 84.  3. ... 70.  3. 59.]\n",
      " [28. 22.  3. ... 31.  3. 63.]\n",
      " [18. 19.  0. ... 43. 65. 66.]]\n",
      "Batch 79: loss = 3.0566611289978027, acc = 0.1796875\n",
      "[[62. 61.  1. ... 84.  3. 30.]\n",
      " [17. 29. 84. ...  3. 58. 63.]\n",
      " [ 1. 79. 66. ... 28. 62. 63.]\n",
      " ...\n",
      " [17. 64.  1. ... 61. 18.  1.]\n",
      " [17. 61.  1. ... 84.  3. 32.]\n",
      " [69.  1. 45. ... 28. 34.  1.]]\n",
      "Batch 80: loss = 2.877868175506592, acc = 0.2080078125\n",
      "[[ 3. 28. 29. ... 62. 61. 29.]\n",
      " [61.  1.  3. ... 66. 60.  1.]\n",
      " [84.  3. 32. ... 84.  3. 31.]\n",
      " ...\n",
      " [12. 61. 17. ... 58. 59. 58.]\n",
      " [70.  3. 64. ...  1. 47. 58.]\n",
      " [ 3. 31. 22. ... 25. 84.  0.]]\n",
      "Batch 81: loss = 3.063302516937256, acc = 0.1748046875\n",
      "[[84.  3. 29. ... 34. 84.  3.]\n",
      " [31. 58. 77. ... 33.  1. 31.]\n",
      " [ 3. 58. 63. ...  1.  3. 29.]\n",
      " ...\n",
      " [76. 62.  0. ...  3. 63. 62.]\n",
      " [77. 77. 66. ... 21. 14. 23.]\n",
      " [61. 84.  3. ... 61. 84.  3.]]\n",
      "Batch 82: loss = 3.143832206726074, acc = 0.1748046875\n",
      "[[30.  3. 28. ... 66. 71. 64.]\n",
      " [33. 32. 12. ... 22.  3. 63.]\n",
      " [70.  3. 28. ... 28. 33. 28.]\n",
      " ...\n",
      " [61.  1. 28. ... 34.  3. 29.]\n",
      " [ 0. 38. 25. ...  3. 58. 28.]\n",
      " [30.  3. 62. ... 34.  3. 34.]]\n",
      "Batch 83: loss = 3.0165915489196777, acc = 0.1923828125\n",
      "[[65. 58. 70. ... 28. 17. 28.]\n",
      " [26. 62. 63. ... 33.  1.  3.]\n",
      " [ 1. 61. 62. ...  1.  3. 28.]\n",
      " ...\n",
      " [17. 61.  1. ... 28. 17. 63.]\n",
      " [28.  1.  3. ... 64.  1. 58.]\n",
      " [28. 34.  1. ... 17. 62. 84.]]\n",
      "Batch 84: loss = 2.987359046936035, acc = 0.1884765625\n",
      "[[84.  3. 34. ... 29. 34. 84.]\n",
      " [30. 70.  3. ... 31. 12. 33.]\n",
      " [22.  3. 33. ... 84.  3. 31.]\n",
      " ...\n",
      " [84.  3. 32. ... 84.  3. 31.]\n",
      " [17. 62. 84. ...  1. 63. 62.]\n",
      " [ 3. 34.  3. ...  1. 28.  1.]]\n",
      "Batch 85: loss = 2.8812522888183594, acc = 0.2060546875\n",
      "[[54.  0.  3. ... 17. 62. 84.]\n",
      " [28.  1. 29. ... 64. 84. 63.]\n",
      " [ 3. 28. 61. ... 40. 78. 76.]\n",
      " ...\n",
      " [ 3. 61. 18. ... 76. 62.  0.]\n",
      " [62. 84.  3. ... 66. 71. 64.]\n",
      " [50. 58. 71. ... 66. 77. 66.]]\n",
      "Batch 86: loss = 3.0345849990844727, acc = 0.1650390625\n",
      "[[ 3. 34.  3. ... 18. 84. 84.]\n",
      " [26. 62. 63. ...  1. 12. 63.]\n",
      " [66. 60.  1. ... 18. 28. 14.]\n",
      " ...\n",
      " [46. 25. 37. ... 62. 63. 64.]\n",
      " [65. 58. 70. ... 28. 84.  3.]\n",
      " [72. 71. 11. ... 60. 34. 32.]]\n",
      "Batch 87: loss = 3.17026948928833, acc = 0.1484375\n",
      "[[ 0.  3. 34. ... 31.  3. 28.]\n",
      " [17. 59. 84. ... 62. 75. 62.]\n",
      " [17. 29. 14. ... 29. 60. 84.]\n",
      " ...\n",
      " [ 1.  3. 31. ...  3. 34.  3.]\n",
      " [34.  3. 29. ...  3. 28. 70.]\n",
      " [84. 26. 60. ... 25.  0. 33.]]\n",
      "Batch 88: loss = 3.017911434173584, acc = 0.193359375\n",
      "[[17. 28. 84. ...  1.  8. 41.]\n",
      " [ 1. 30. 58. ... 69.  1. 45.]\n",
      " [ 0.  3. 31. ...  3. 61. 17.]\n",
      " ...\n",
      " [31. 34. 28. ... 18. 84.  3.]\n",
      " [ 3. 61. 62. ... 34. 84.  3.]\n",
      " [14. 17. 34. ...  3. 31.  3.]]\n",
      "Batch 89: loss = 3.0516326427459717, acc = 0.1728515625\n",
      "[[72. 75. 77. ... 14. 17. 84.]\n",
      " [72. 80. 62. ...  1. 61.  0.]\n",
      " [62.  1. 63. ... 14. 60. 10.]\n",
      " ...\n",
      " [31.  3. 28. ... 62. 18.  1.]\n",
      " [28. 70.  3. ... 59.  3.  3.]\n",
      " [28. 18.  1. ... 84.  3. 30.]]\n",
      "Batch 90: loss = 3.1139893531799316, acc = 0.1904296875\n",
      "[[ 3. 34.  3. ... 31. 84.  0.]\n",
      " [29. 34. 84. ... 29. 84.  3.]\n",
      " [ 3. 64. 17. ... 58. 76. 76.]\n",
      " ...\n",
      " [28. 29. 14. ... 28. 28. 84.]\n",
      " [33.  3. 64. ... 40. 78. 76.]\n",
      " [ 3. 64. 58. ... 31.  3. 61.]]\n",
      "Batch 91: loss = 2.9526102542877197, acc = 0.2080078125\n",
      "[[ 3. 30.  3. ... 34.  1.  3.]\n",
      " [30.  3. 60. ...  3. 61. 62.]\n",
      " [ 1. 42.  7. ... 80. 62.  0.]\n",
      " ...\n",
      " [54.  0.  3. ...  0. 46. 25.]\n",
      " [66. 60.  1. ... 32. 84.  3.]\n",
      " [18.  1. 12. ...  0. 46. 25.]]\n",
      "Batch 92: loss = 2.9916226863861084, acc = 0.185546875\n",
      "[[29. 70.  3. ... 34.  3. 29.]\n",
      " [56. 64. 84. ... 77. 77. 66.]\n",
      " [40. 25. 21. ...  3. 60. 17.]\n",
      " ...\n",
      " [33. 47. 29. ... 31.  3. 61.]\n",
      " [31.  3. 33. ... 84.  0.  3.]\n",
      " [50. 72. 69. ...  1. 63. 62.]]\n",
      "Batch 93: loss = 3.004767894744873, acc = 0.181640625\n",
      "[[28. 34. 84. ...  5.  1. 41.]\n",
      " [71. 64. 65. ... 25. 28.  0.]\n",
      " [25. 84.  0. ... 58. 17. 63.]\n",
      " ...\n",
      " [62. 61.  1. ... 61. 29. 28.]\n",
      " [32. 70.  3. ... 63. 17. 58.]\n",
      " [61. 84.  0. ... 84. 63. 62.]]\n",
      "Batch 94: loss = 2.9218974113464355, acc = 0.203125\n",
      "[[72. 77. 77. ...  3. 34. 17.]\n",
      " [28. 84.  3. ...  1. 61. 17.]\n",
      " [ 1.  3. 30. ... 71.  1. 43.]\n",
      " ...\n",
      " [84.  3. 31. ... 28. 22.  3.]\n",
      " [ 1. 58. 63. ... 63. 84.  0.]\n",
      " [61.  1. 56. ... 61. 63.  1.]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 95: loss = 2.8708009719848633, acc = 0.2158203125\n",
      "[[34.  1.  3. ... 17. 61.  1.]\n",
      " [63. 84.  3. ... 28. 17. 63.]\n",
      " [72. 80. 75. ...  1. 45. 72.]\n",
      " ...\n",
      " [58. 17. 28. ... 18.  0. 47.]\n",
      " [ 3. 31.  3. ... 25.  1. 18.]\n",
      " [28. 61. 63. ... 71. 68. 76.]]\n",
      "Batch 96: loss = 2.889787197113037, acc = 0.205078125\n",
      "[[ 3. 28. 70. ... 62. 63. 84.]\n",
      " [84.  3. 28. ... 56. 61. 62.]\n",
      " [80. 62.  0. ... 84.  3. 34.]\n",
      " ...\n",
      " [25. 46. 70. ... 14. 23.  0.]\n",
      " [16. 21.  0. ...  1. 73.  1.]\n",
      " [ 1. 72. 63. ... 14. 35. 37.]]\n",
      "Batch 97: loss = 3.033266067504883, acc = 0.1708984375\n",
      "[[64. 17. 64. ...  3. 31. 22.]\n",
      " [ 1. 58. 17. ... 17. 63.  1.]\n",
      " [70.  3. 61. ... 61. 17. 60.]\n",
      " ...\n",
      " [38. 25. 31. ...  1.  3. 28.]\n",
      " [16. 18. 19. ...  1. 32. 17.]\n",
      " [33.  0. 40. ...  3. 29. 61.]]\n",
      "Batch 98: loss = 3.0093603134155273, acc = 0.1845703125\n",
      "[[ 3. 28. 33. ... 32. 84.  3.]\n",
      " [63. 62. 63. ... 61. 18.  1.]\n",
      " [84.  3. 34. ...  1. 63. 62.]\n",
      " ...\n",
      " [22.  3. 34. ... 29.  0. 84.]\n",
      " [60. 84.  3. ...  3. 29. 18.]\n",
      " [61.  1.  3. ...  3. 33. 32.]]\n",
      "Batch 99: loss = 2.8540709018707275, acc = 0.22265625\n",
      "[[28. 22.  3. ... 18.  1. 12.]\n",
      " [12. 61. 17. ... 59. 58. 76.]\n",
      " [63. 84.  3. ... 30. 22.  3.]\n",
      " ...\n",
      " [63. 14. 17. ... 28. 22. 14.]\n",
      " [ 1.  3. 28. ...  0.  3. 28.]\n",
      " [32.  1.  3. ... 58. 64. 84.]]\n",
      "Batch 100: loss = 2.81121826171875, acc = 0.234375\n",
      "[[34. 17. 25. ... 25. 31. 72.]\n",
      " [62.  0. 46. ... 25.  3. 31.]\n",
      " [60. 61. 60. ... 84. 34. 17.]\n",
      " ...\n",
      " [62.  3. 64. ... 64. 63.  1.]\n",
      " [ 3. 62. 60. ... 62. 84.  3.]\n",
      " [ 0.  3. 31. ... 84.  0.  0.]]\n",
      "Batch 101: loss = 2.934945583343506, acc = 0.2080078125\n",
      "[[71.  1. 40. ... 38. 25. 31.]\n",
      " [ 3. 31. 32. ... 70.  3. 28.]\n",
      " [34.  1. 34. ... 65. 58. 70.]\n",
      " ...\n",
      " [63. 62. 61. ... 10.  3. 58.]\n",
      " [31.  3. 63. ... 84.  3. 31.]\n",
      " [ 0. 51. 25. ... 58. 76. 62.]]\n",
      "Batch 102: loss = 2.9974610805511475, acc = 0.1962890625\n",
      "[[ 0. 28. 84. ... 33.  1.  3.]\n",
      " [34. 33. 84. ...  1. 61. 62.]\n",
      " [ 1. 40. 78. ... 60. 62.  1.]\n",
      " ...\n",
      " [64. 63.  1. ... 62.  0.  5.]\n",
      " [ 3. 61. 63. ...  1. 40. 78.]\n",
      " [ 0. 46. 25. ... 28.  3. 62.]]\n",
      "Batch 103: loss = 2.956305980682373, acc = 0.1875\n",
      "[[34.  3. 34. ... 62. 17. 61.]\n",
      " [63. 84.  3. ... 84.  3. 32.]\n",
      " [ 3. 31. 70. ... 28. 60. 62.]\n",
      " ...\n",
      " [ 1. 41. 72. ... 38. 25. 28.]\n",
      " [76. 66. 60. ... 28. 28.  1.]\n",
      " [63. 58.  1. ... 84.  3. 31.]]\n",
      "Batch 104: loss = 2.8138980865478516, acc = 0.22265625\n",
      "[[84.  3. 28. ... 29. 60. 84.]\n",
      " [70.  3. 32. ... 17. 28. 84.]\n",
      " [ 1.  3. 31. ... 18.  1. 12.]\n",
      " ...\n",
      " [ 0. 43. 25. ... 28. 17. 28.]\n",
      " [60. 28. 28. ... 29. 29.  1.]\n",
      " [ 3. 62. 63. ...  3. 28. 28.]]\n",
      "Batch 105: loss = 2.771090030670166, acc = 0.2275390625\n",
      "[[ 3. 31.  3. ... 58. 59. 58.]\n",
      " [ 3. 34.  3. ... 47. 65. 62.]\n",
      " [28. 17. 84. ...  1. 28. 64.]\n",
      " ...\n",
      " [ 1. 28. 34. ...  1. 60. 61.]\n",
      " [ 3. 28.  3. ...  3. 31.  3.]\n",
      " [28. 84.  3. ...  3. 28. 18.]]\n",
      "Batch 106: loss = 2.824322462081909, acc = 0.2216796875\n",
      "[[76. 62.  0. ... 17. 33. 84.]\n",
      " [ 1. 30. 58. ... 14. 23.  0.]\n",
      " [28. 84. 57. ... 70. 58. 71.]\n",
      " ...\n",
      " [62. 84.  3. ...  3. 28. 14.]\n",
      " [63. 64. 58. ...  3. 62. 63.]\n",
      " [84.  3. 28. ... 60. 84.  3.]]\n",
      "Batch 107: loss = 2.8435311317443848, acc = 0.2216796875\n",
      "[[ 3. 30. 14. ...  3. 28. 17.]\n",
      " [38. 25. 34. ... 34. 18.  1.]\n",
      " [ 0.  5.  1. ... 14. 23.  0.]\n",
      " ...\n",
      " [62.  3. 62. ...  1. 40. 78.]\n",
      " [62.  1.  3. ... 40. 78. 76.]\n",
      " [28.  3. 62. ...  1. 63. 62.]]\n",
      "Batch 108: loss = 2.7772090435028076, acc = 0.2373046875\n",
      "[[60. 84.  3. ... 62. 61.  3.]\n",
      " [34. 28. 29. ...  3. 62. 14.]\n",
      " [38. 25. 34. ... 61. 17. 60.]\n",
      " ...\n",
      " [76. 66. 60. ... 34. 17. 34.]\n",
      " [66. 60.  1. ... 31.  3. 63.]\n",
      " [62. 84.  3. ... 62. 63. 63.]]\n",
      "Batch 109: loss = 2.6875505447387695, acc = 0.2431640625\n",
      "[[30. 14. 62. ... 14. 60.  3.]\n",
      " [17. 63. 14. ...  3. 31.  3.]\n",
      " [ 1. 29. 17. ... 32. 18.  1.]\n",
      " ...\n",
      " [ 1. 34. 17. ... 84.  0. 53.]\n",
      " [64. 58.  1. ...  3. 61. 60.]\n",
      " [ 1.  3. 28. ... 28. 84.  3.]]\n",
      "Batch 110: loss = 2.8363776206970215, acc = 0.228515625\n",
      "[[60.  1. 64. ...  1. 60.  7.]\n",
      " [61. 29. 28. ...  1. 41. 72.]\n",
      " [12. 32. 17. ... 18. 84.  3.]\n",
      " ...\n",
      " [17.  3. 34. ... 21. 84.  3.]\n",
      " [29. 84.  3. ...  1. 64. 17.]\n",
      " [31.  3. 63. ... 18. 84.  0.]]\n",
      "Batch 111: loss = 2.8449063301086426, acc = 0.22265625\n",
      "[[64. 62.  1. ... 47. 75. 58.]\n",
      " [77. 77. 66. ... 80. 62.  0.]\n",
      " [28. 70.  3. ...  3. 61. 17.]\n",
      " ...\n",
      " [31. 22.  3. ... 34. 84.  0.]\n",
      " [62. 84.  3. ...  3. 28.  3.]\n",
      " [ 3. 28.  3. ... 29. 60. 84.]]\n",
      "Batch 112: loss = 2.8083200454711914, acc = 0.2373046875\n",
      "[[61. 11.  1. ... 84. 54.  0.]\n",
      " [40. 25. 21. ... 84.  0.  3.]\n",
      " [34.  1. 34. ...  1. 60. 29.]\n",
      " ...\n",
      " [ 3. 33.  3. ... 25.  1. 17.]\n",
      " [28. 18.  1. ... 58. 76. 62.]\n",
      " [ 3. 28.  3. ...  7. 76.  1.]]\n",
      "Batch 113: loss = 2.768315553665161, acc = 0.244140625\n",
      "[[ 3. 34. 22. ... 31.  3. 26.]\n",
      " [29. 70.  3. ...  3. 61. 29.]\n",
      " [28. 84.  3. ... 28.  1. 29.]\n",
      " ...\n",
      " [24. 21.  0. ... 69.  1. 45.]\n",
      " [ 0. 46. 25. ... 62. 18. 14.]\n",
      " [44. 78. 58. ... 25. 21. 14.]]\n",
      "Batch 114: loss = 2.912618637084961, acc = 0.2216796875\n",
      "[[28. 33. 31. ... 28. 17. 61.]\n",
      " [29.  1. 29. ... 28.  1.  3.]\n",
      " [17. 60. 84. ... 34.  1. 60.]\n",
      " ...\n",
      " [72. 80. 62. ... 31. 84.  3.]\n",
      " [17. 60. 14. ... 33. 14. 17.]\n",
      " [23.  0. 38. ...  1. 12.  3.]]\n",
      "Batch 115: loss = 2.8427305221557617, acc = 0.228515625\n",
      "[[84.  3. 34. ...  0. 26. 33.]\n",
      " [34.  3. 29. ... 29.  1. 29.]\n",
      " [17. 62. 84. ...  0.  0. 51.]\n",
      " ...\n",
      " [30.  3. 32. ... 31. 34. 29.]\n",
      " [32. 84.  0. ...  3. 64. 18.]\n",
      " [30. 70.  3. ... 29. 11. 31.]]\n",
      "Batch 116: loss = 2.8150267601013184, acc = 0.2265625\n",
      "[[31. 33.  1. ... 71. 64. 65.]\n",
      " [25. 84.  0. ... 75. 75.  1.]\n",
      " [25.  1. 21. ... 28. 11.  1.]\n",
      " ...\n",
      " [84. 61. 29. ...  3. 31. 17.]\n",
      " [14. 17. 62. ... 17. 64. 62.]\n",
      " [33.  1. 29. ... 60. 28. 60.]]\n",
      "Batch 117: loss = 2.926863193511963, acc = 0.2119140625\n",
      "[[58. 70.  1. ... 32. 28. 60.]\n",
      " [43. 65. 66. ... 62. 17. 61.]\n",
      " [79. 66. 58. ... 84.  3. 34.]\n",
      " ...\n",
      " [33. 84.  3. ... 34.  1. 32.]\n",
      " [ 1.  3. 28. ... 14. 17. 32.]\n",
      " [84. 62. 17. ... 84.  3. 29.]]\n",
      "Batch 118: loss = 2.782355308532715, acc = 0.2451171875\n",
      "[[ 1. 62. 17. ... 58. 17. 63.]\n",
      " [84.  1.  3. ... 70.  3. 64.]\n",
      " [ 3. 29. 60. ...  3. 34.  3.]\n",
      " ...\n",
      " [34. 28. 84. ... 56. 34.  1.]\n",
      " [84.  0.  3. ... 64. 18. 14.]\n",
      " [59.  3. 63. ... 17. 34. 84.]]\n",
      "Batch 119: loss = 2.7212114334106445, acc = 0.2646484375\n",
      "[[84.  3. 28. ...  1. 32. 28.]\n",
      " [63. 62. 84. ... 28. 29. 60.]\n",
      " [29. 60. 61. ... 31.  3. 61.]\n",
      " ...\n",
      " [28. 17. 34. ...  0.  0.  0.]\n",
      " [17. 62. 14. ... 77. 77. 66.]\n",
      " [ 3. 33. 22. ... 29.  1.  3.]]\n",
      "Batch 120: loss = 2.8013296127319336, acc = 0.2578125\n",
      "[[60. 84.  3. ... 84.  0.  0.]\n",
      " [84.  0.  3. ...  0.  0.  0.]\n",
      " [62. 61.  1. ... 63. 84.  3.]\n",
      " ...\n",
      " [51. 25.  1. ...  1. 31. 62.]\n",
      " [71. 64. 65. ... 28.  1.  3.]\n",
      " [33. 22.  3. ... 60.  1. 62.]]\n",
      "Batch 121: loss = 2.717653274536133, acc = 0.25390625\n",
      "[[ 0. 51. 25. ... 29. 66. 69.]\n",
      " [51. 25.  1. ... 21. 14. 23.]\n",
      " [28. 22.  3. ... 70.  1. 40.]\n",
      " ...\n",
      " [80. 65. 78. ...  3. 32.  3.]\n",
      " [34.  3. 34. ... 33. 28. 61.]\n",
      " [60. 28. 84. ... 66. 71. 64.]]\n",
      "Batch 122: loss = 2.817592144012451, acc = 0.2275390625\n",
      "[[69. 82.  1. ... 34.  1. 61.]\n",
      " [ 0. 38. 25. ... 64. 63. 84.]\n",
      " [78. 76. 66. ... 29. 28. 33.]\n",
      " ...\n",
      " [29. 17. 32. ...  3. 28. 18.]\n",
      " [ 1. 63. 62. ... 29. 60.  1.]\n",
      " [65. 58. 70. ...  3. 28.  3.]]\n",
      "Batch 123: loss = 2.7893738746643066, acc = 0.2294921875\n",
      "[[18. 84.  3. ...  3. 29. 61.]\n",
      " [ 0.  3. 32. ...  1. 62. 18.]\n",
      " [84.  3. 31. ... 29. 84.  3.]\n",
      " ...\n",
      " [ 1. 12. 28. ... 33.  1. 28.]\n",
      " [62. 61. 60. ... 78. 75. 71.]\n",
      " [62. 17. 61. ... 18.  1. 61.]]\n",
      "Batch 124: loss = 2.662649631500244, acc = 0.2802734375\n",
      "[[64.  1. 29. ... 61. 29.  1.]\n",
      " [84. 84.  0. ...  3. 61. 18.]\n",
      " [33.  3. 28. ... 61. 29. 34.]\n",
      " ...\n",
      " [60. 62. 84. ...  1. 36. 76.]\n",
      " [73. 66. 68. ... 25. 21. 14.]\n",
      " [17. 62. 84. ... 84.  3. 28.]]\n",
      "Batch 125: loss = 2.648763418197632, acc = 0.2744140625\n",
      "[[34. 29. 61. ... 62. 34. 29.]\n",
      " [ 1.  3. 31. ... 72. 80. 71.]\n",
      " [84.  3. 34. ... 26. 33. 18.]\n",
      " ...\n",
      " [69. 58. 71. ... 66. 58.  1.]\n",
      " [23.  0. 38. ... 60. 29. 60.]\n",
      " [ 3. 28. 29. ... 32. 70.  3.]]\n",
      "Batch 126: loss = 2.759761095046997, acc = 0.2705078125\n",
      "Saved checkpoint to weights.1.h5\n",
      "training done...........\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    parser = argparse.ArgumentParser(description='Train the model on some text.')\n",
    "    parser.add_argument('--input', default='input.txt', help='name of the text file to train from')\n",
    "    parser.add_argument('--epochs', type=int, default=100, help='number of epochs to train for')\n",
    "    parser.add_argument('--freq', type=int, default=10, help='checkpoint save frequency')\n",
    "    args, unknown = parser.parse_known_args()\n",
    "\n",
    "    if not os.path.exists(LOG_DIR):\n",
    "        os.makedirs(LOG_DIR)\n",
    "\n",
    "epochs = args.epochs\n",
    "save_freq = args.freq\n",
    "text = open(os.path.join(DATA_DIR, args.input)).read()\n",
    "\n",
    "print(\"processing\")\n",
    "# character to index and vice-versa mappings\n",
    "char_to_idx = { ch: i for (i, ch) in enumerate(sorted(list(set(text)))) }\n",
    "print(\"Number of unique characters: \" + str(len(char_to_idx))) #86\n",
    "\n",
    "idx_to_char = { i: ch for (ch, i) in char_to_idx.items() }\n",
    "vocab_size = len(char_to_idx)\n",
    "print(\"processing done\")\n",
    "\n",
    "print(\"creating model\")\n",
    "#model_architecture    \n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 512, batch_input_shape=(BATCH_SIZE, SEQ_LENGTH)))\n",
    "for i in range(3):\n",
    "    model.add(LSTM(256, return_sequences=True, stateful=True))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "model.add(TimeDistributed(Dense(vocab_size))) \n",
    "model.add(Activation('softmax'))\n",
    "print(\"model created\")\n",
    "    \n",
    "model.summary()\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "#Train data generation\n",
    "print(\"training data\")\n",
    "T = np.asarray([char_to_idx[c] for c in text], dtype=np.int32) #convert complete text into numerical indices\n",
    "\n",
    "print(\"Length of text:\" + str(T.size)) #129,665\n",
    "\n",
    "steps_per_epoch = (len(text) / BATCH_SIZE - 1) / SEQ_LENGTH  \n",
    "\n",
    "log = TrainLogger('training_log.csv')\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print('\\nEpoch {}/{}'.format(epoch + 1, epochs))\n",
    "        \n",
    "    losses, accs = [], []\n",
    "\n",
    "    for i, (X, Y) in enumerate(read_batches(T, vocab_size)):\n",
    "            \n",
    "        print(X);\n",
    "\n",
    "        loss, acc = model.train_on_batch(X, Y)\n",
    "        print('Batch {}: loss = {}, acc = {}'.format(i + 1, loss, acc))\n",
    "        losses.append(loss)\n",
    "        accs.append(acc)\n",
    "\n",
    "    log.add_entry(np.average(losses), np.average(accs))\n",
    "    \n",
    "    if (epoch + 1) % save_freq == 0:\n",
    "            save_weights(epoch + 1, model)\n",
    "            print('Saved checkpoint to', 'weights.{}.h5'.format(epoch + 1))\n",
    "\n",
    "print(\"training done...........\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (1, 1, 512)               44032     \n",
      "_________________________________________________________________\n",
      "lstm_12 (LSTM)               (1, 1, 256)               787456    \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (1, 1, 256)               0         \n",
      "_________________________________________________________________\n",
      "lstm_13 (LSTM)               (1, 1, 256)               525312    \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (1, 1, 256)               0         \n",
      "_________________________________________________________________\n",
      "lstm_14 (LSTM)               (1, 1, 256)               525312    \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (1, 1, 256)               0         \n",
      "_________________________________________________________________\n",
      "time_distributed_4 (TimeDist (1, 1, 86)                22102     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (1, 1, 86)                0         \n",
      "=================================================================\n",
      "Total params: 1,904,214\n",
      "Trainable params: 1,904,214\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "sampled\n",
      "[17, 64, 14, 17, 63, 14, 17, 62, 14, 17, 1, 61, 18, 14, 17, 62, 14, 17, 60, 14, 17, 84, 0, 62, 14, 17, 61, 14, 17, 60, 14, 17, 29, 14, 17, 28, 14, 17, 34, 14, 17, 1, 62, 14, 17, 61, 14, 17, 60, 14, 17, 29, 14, 17, 28, 14, 17, 34, 14, 17, 84, 29, 14, 17, 34, 14, 17, 29, 14, 17, 61, 14, 17, 64, 14, 17, 61, 14, 17, 1, 59, 14, 17, 58, 14, 17, 64, 14, 17, 63, 14, 17, 62, 14, 17, 61, 14, 17, 84, 54, 0, 32, 28, 60, 1, 29, 60, 28, 84, 34, 19, 84, 84, 0, 43, 25, 33, 0, 29, 60, 84, 61, 18, 14, 17, 29, 14, 17, 61, 14, 17, 29, 14, 17, 1, 62, 18, 14, 17, 29, 14, 17, 62, 14, 17, 29, 14, 17, 84, 61, 18, 14, 17, 29, 14, 17, 61, 14, 17, 60, 14, 17, 1, 29, 28, 34, 84, 54, 0, 32, 14, 17, 31, 14, 17, 33, 14, 17, 28, 14, 17, 61, 14, 17, 28, 14, 17, 1, 64, 14, 17, 29, 14, 17, 60, 14, 17, 28, 14, 17, 84, 0, 60, 28, 14, 17, 29, 14, 17, 60, 14, 17, 28, 14, 17, 1, 60, 14, 17, 29, 14, 17, 28, 14, 17, 34, 14, 17, 84, 32, 18, 1, 28, 60, 29, 84, 84, 0, 60, 60, 60, 1, 60, 34, 29, 84, 61, 14, 17, 29, 14, 17, 29, 14, 17, 61, 14, 17, 60, 14, 17, 1, 29, 28, 34, 84, 54, 0, 32, 28, 60, 1, 29, 60, 28, 84, 34, 19, 84, 84, 0, 43, 25, 35, 0, 29, 60, 84, 61, 18, 14, 17, 29, 14, 17, 61, 14, 17, 29, 14, 17, 1, 62, 18, 14, 17, 29, 14, 17, 62, 14, 17, 29, 14, 17, 84, 61, 14, 17, 34, 14, 17, 29, 14, 17, 61, 14, 17, 64, 14, 17, 61, 14, 17, 1, 59, 14, 17, 58, 14, 17, 63, 14, 17, 84, 0, 63, 18, 14, 17, 64, 14, 17, 63, 14, 17, 62, 14, 17, 1, 61, 18, 14, 17, 62, 14, 17, 61, 14, 17, 29, 14, 17, 84, 61, 18, 14, 17, 29, 14, 17, 61, 14, 17, 60, 14, 17, 1, 29, 28, 34, 84, 54, 0, 32, 28, 60, 1, 29, 60, 28, 84, 34, 19, 84, 84, 0, 0, 0, 51, 25, 1, 17, 19, 23, 0, 47, 25, 46, 75, 58, 71, 61, 72, 71, 1, 45, 58, 60, 62, 0, 5, 1, 41, 72, 77, 77, 66, 71, 64, 65, 58, 70, 1, 40, 78, 76, 66, 60, 1, 31, 58, 77, 58, 59, 58, 76, 62, 0, 46, 25, 47, 75, 58, 61, 11, 1, 58, 75, 75, 1, 43, 65, 66, 69, 1, 45, 72, 80, 62, 0, 40, 25, 21, 14, 23, 0, 38, 25, 31, 0, 3, 31, 3, 61, 17, 61, 1, 3, 28, 3, 60, 29, 28, 84, 3, 34, 3, 61, 17, 61, 1, 3, 31, 3, 28, 17, 61, 84, 3, 34, 3, 29, 17, 61, 1, 3, 31, 3, 28, 17, 61, 84, 3, 32, 70, 3, 34, 18, 1, 12, 34, 25, 25, 0, 64, 84, 3, 31, 3, 63, 62, 61, 1, 62, 61, 63, 84, 3, 28, 22, 3, 28, 60, 62, 1, 62, 60, 28, 84, 3, 34, 3, 29, 60, 61, 1, 3, 28, 22, 3, 62, 60, 28, 84, 3, 31, 3, 61, 63, 62, 1, 61, 17, 25, 25, 0, 29, 84, 3, 31, 3, 28, 17, 61, 1, 61, 17, 63, 84, 3, 34, 3, 62, 61, 29, 1, 3, 28, 22, 3, 28, 63, 64, 84, 3, 31, 3, 58, 63, 61, 1, 3, 28, 22, 3, 62, 58, 60, 84, 3, 31, 3, 61, 18, 1, 61, 17, 84, 84, 0, 0, 0, 51, 25, 1, 17, 22, 21, 0, 47, 25, 46, 60, 72, 77, 76, 59, 75, 72, 72, 70, 62, 1, 37, 66, 64, 0, 5, 1, 41, 72, 77, 77, 66, 71, 64, 65, 58, 70, 1, 40, 78, 76, 66, 60, 1, 31, 58, 77, 58, 59, 58, 76, 62, 0, 46, 25, 47, 75, 58, 61, 11, 1, 79, 66, 58, 1, 32, 33, 0, 52, 25, 28, 29, 0, 40, 25, 21, 14, 23, 0, 38, 25, 31, 0, 43, 25, 28, 0, 28, 84, 3, 31, 3, 61, 17, 61, 1, 61, 60, 61, 84, 3, 34, 3, 29, 17, 61, 1, 3, 31, 14, 63, 10, 3, 28, 17, 61, 84, 3, 31, 3, 61, 18, 1, 3, 28, 22, 3, 28, 61, 60, 84, 3, 31, 3, 61, 18, 1, 61, 17, 25, 84, 0, 0, 0, 51, 25, 1, 17, 16, 0, 47, 25, 29, 66, 60, 68, 1, 46, 82, 1, 40, 72, 80, 66, 62, 0, 5, 1, 41, 72, 77, 77, 66, 71, 64, 65, 58, 70, 1, 40, 78, 76, 66, 60, 1, 31, 58, 77, 58, 59, 58, 76, 62, 0, 46, 25, 40, 66, 68, 62, 1, 45, 66, 60, 65, 58, 75, 61, 76, 72, 71, 1, 16, 21, 13, 16, 17, 13, 23, 24, 11, 1, 79, 66, 58, 1, 43, 65, 66, 69, 1, 45, 72, 80, 62, 0, 40, 25, 21, 14, 23, 0, 38, 25, 34, 0, 3, 34, 3, 34, 17, 34, 1, 3, 31, 3, 28, 17, 28, 84, 3, 34, 3, 29, 17, 60, 1, 61, 29, 34, 84, 3, 30, 3, 32, 17, 32, 1, 60, 17, 29, 84, 3, 28, 70, 3, 28, 29, 34, 1, 3, 31, 22, 3, 33, 32, 31, 84, 3, 34, 3, 34, 17, 34, 1, 3, 31, 3, 28, 17, 28, 84, 3, 34, 3, 29, 17, 60, 1, 61, 29, 34, 84, 54, 0, 3, 30, 3, 32, 33, 34, 1, 3, 31, 22, 3, 28, 17, 33, 84, 3, 34, 3, 34, 18, 1, 12, 34, 17, 25, 25, 0, 28, 84, 3, 34, 3, 29, 60, 29, 1, 64, 29, 60, 84, 3, 34, 3, 61, 17, 29]\n",
      "2g/2f/2e/2 d3/2e/2c/2|\n",
      "e/2d/2c/2B/2A/2G/2 e/2d/2c/2B/2A/2G/2|B/2G/2B/2d/2g/2d/2 b/2a/2g/2f/2e/2d/2|\\\n",
      "EAc BcA|G4||\n",
      "P:F\n",
      "Bc|d3/2B/2d/2B/2 e3/2B/2e/2B/2|d3/2B/2d/2c/2 BAG|\\\n",
      "E/2D/2F/2A/2d/2A/2 g/2B/2c/2A/2|\n",
      "cA/2B/2c/2A/2 c/2B/2A/2G/2|E3 AcB||\n",
      "ccc cGB|d/2B/2B/2d/2c/2 BAG|\\\n",
      "EAc BcA|G4||\n",
      "P:H\n",
      "Bc|d3/2B/2d/2B/2 e3/2B/2e/2B/2|d/2G/2B/2d/2g/2d/2 b/2a/2f/2|\n",
      "f3/2g/2f/2e/2 d3/2e/2d/2B/2|d3/2B/2d/2c/2 BAG|\\\n",
      "EAc BcA|G4||\n",
      "\n",
      "\n",
      "X: 248\n",
      "T:Srandon Race\n",
      "% Nottingham Music Database\n",
      "S:Trad, arr Phil Rowe\n",
      "M:6/8\n",
      "K:D\n",
      "\"D\"d2d \"A\"cBA|\"G\"d2d \"D\"A2d|\"G\"B2d \"D\"A2d|\"Em\"G3 -G::\n",
      "g|\"D\"fed edf|\"A7\"Ace ecA|\"G\"Bcd \"A7\"ecA|\"D\"dfe d2::\n",
      "B|\"D\"A2d d2f|\"G\"edB \"A7\"Afg|\"D\"afd \"A7\"eac|\"D\"d3 d2||\n",
      "\n",
      "\n",
      "X: 276\n",
      "T:Scotsbroome Jig\n",
      "% Nottingham Music Database\n",
      "S:Trad, via EF\n",
      "Y:AB\n",
      "M:6/8\n",
      "K:D\n",
      "P:A\n",
      "A|\"D\"d2d dcd|\"G\"B2d \"D/f+\"A2d|\"D\"d3 \"A7\"Adc|\"D\"d3 d2:|\n",
      "\n",
      "\n",
      "X: 21\n",
      "T:Bick Sy Mowie\n",
      "% Nottingham Music Database\n",
      "S:Mike Richardson 16.12.89, via Phil Rowe\n",
      "M:6/8\n",
      "K:G\n",
      "\"G\"G2G \"D\"A2A|\"G\"B2c dBG|\"C\"E2E c2B|\"Am\"ABG \"D7\"FED|\"G\"G2G \"D\"A2A|\"G\"B2c dBG|\\\n",
      "\"C\"EFG \"D7\"A2F|\"G\"G3 -G2::\n",
      "A|\"G\"BcB gBc|\"G\"d2B\n"
     ]
    }
   ],
   "source": [
    "MODEL_DIR = './model'\n",
    "model2 = Sequential()\n",
    "model2.add(Embedding(vocab_size, 512, batch_input_shape=(1,1)))\n",
    "for i in range(3):\n",
    "    model2.add(LSTM(256, return_sequences=True, stateful=True))\n",
    "    model2.add(Dropout(0.2))\n",
    "\n",
    "model2.add(TimeDistributed(Dense(vocab_size))) \n",
    "model2.add(Activation('softmax'))\n",
    "\n",
    "model2.load_weights(os.path.join(MODEL_DIR, 'weights.100.h5'.format(epoch)))\n",
    "model2.summary()\n",
    "\n",
    "\n",
    "\n",
    "sampled = []\n",
    "for i in range(1024):\n",
    "    batch = np.zeros((1, 1))\n",
    "    if sampled:\n",
    "        batch[0, 0] = sampled[-1]\n",
    "    else:\n",
    "        batch[0, 0] = np.random.randint(vocab_size)\n",
    "    result = model2.predict_on_batch(batch).ravel()\n",
    "    sample = np.random.choice(range(vocab_size), p=result)\n",
    "    sampled.append(sample)\n",
    "\n",
    "print(\"sampled\")\n",
    "print(sampled)\n",
    "print(''.join(idx_to_char[c] for c in sampled))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
